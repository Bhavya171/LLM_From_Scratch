{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30919,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bhavya171/LLM_From_Scratch/blob/main/Project1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project 1 based on chapter 1-5"
      ],
      "metadata": {
        "id": "aYIbLWEuS3V_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have made a dataset1.txt file which contains data from both the books which i will use as the training and validation data."
      ],
      "metadata": {
        "id": "zaqPHnxmS6_v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cloning git repo for supporting files"
      ],
      "metadata": {
        "id": "KqVtg2P5TFjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Bhavya171/LLM_From_Scratch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfwSi5U_BhOW",
        "outputId": "29843b13-bca3-46ac-c10b-70140ceca0fa",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T08:19:11.439627Z",
          "iopub.execute_input": "2025-04-03T08:19:11.439916Z",
          "iopub.status.idle": "2025-04-03T08:19:12.623540Z",
          "shell.execute_reply.started": "2025-04-03T08:19:11.439883Z",
          "shell.execute_reply": "2025-04-03T08:19:12.622487Z"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'LLM_From_Scratch'...\n",
            "remote: Enumerating objects: 60, done.\u001b[K\n",
            "remote: Counting objects: 100% (60/60), done.\u001b[K\n",
            "remote: Compressing objects: 100% (57/57), done.\u001b[K\n",
            "remote: Total 60 (delta 24), reused 4 (delta 1), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (60/60), 2.06 MiB | 8.52 MiB/s, done.\n",
            "Resolving deltas: 100% (24/24), done.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T08:19:12.624635Z",
          "iopub.execute_input": "2025-04-03T08:19:12.624908Z",
          "iopub.status.idle": "2025-04-03T08:19:12.741839Z",
          "shell.execute_reply.started": "2025-04-03T08:19:12.624872Z",
          "shell.execute_reply": "2025-04-03T08:19:12.740694Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIqxXrOBE5Nh",
        "outputId": "1a0db803-b549-4150-ffff-2be9aaf2520e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%cd LLM_From_Scratch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9iTJ4rTL3Qz",
        "outputId": "191ebca1-4d8a-4e79-80a7-ce8fdcbc9a8b",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T08:19:42.682775Z",
          "iopub.execute_input": "2025-04-03T08:19:42.683111Z",
          "iopub.status.idle": "2025-04-03T08:19:42.688597Z",
          "shell.execute_reply.started": "2025-04-03T08:19:42.683082Z",
          "shell.execute_reply": "2025-04-03T08:19:42.687673Z"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/LLM_From_Scratch\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZ1eOEGrMSVf",
        "outputId": "3b5cdf43-296d-4093-d705-24472d636353",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T08:19:52.207123Z",
          "iopub.execute_input": "2025-04-03T08:19:52.207423Z",
          "iopub.status.idle": "2025-04-03T08:19:56.338900Z",
          "shell.execute_reply.started": "2025-04-03T08:19:52.207401Z",
          "shell.execute_reply": "2025-04-03T08:19:56.338073Z"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.9.0\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing neccesary functions from previous chapters"
      ],
      "metadata": {
        "id": "UBy2-AL3TKll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import tiktoken\n",
        "from previous_chapters import GPTModel\n",
        "from previous_chapters import create_dataloader_v1\n",
        "from previous_chapters import generate_text_simple\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n"
      ],
      "metadata": {
        "id": "RB_cOTqXMIb8",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T08:19:57.738038Z",
          "iopub.execute_input": "2025-04-03T08:19:57.738342Z",
          "iopub.status.idle": "2025-04-03T08:20:00.777062Z",
          "shell.execute_reply.started": "2025-04-03T08:19:57.738320Z",
          "shell.execute_reply": "2025-04-03T08:20:00.776388Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,\n",
        "    \"context_length\": 256,\n",
        "    \"emb_dim\": 768,\n",
        "    \"n_heads\": 12,\n",
        "    \"n_layers\": 12,\n",
        "    \"drop_rate\": 0.1,\n",
        "    \"qkv_bias\": False\n",
        "}\n",
        "\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.eval()\n"
      ],
      "metadata": {
        "id": "G1E4mpWsMM43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dedb8234-88ea-4ed1-8193-8700910bc1e0",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T08:20:03.738768Z",
          "iopub.execute_input": "2025-04-03T08:20:03.739236Z",
          "iopub.status.idle": "2025-04-03T08:20:05.145137Z",
          "shell.execute_reply.started": "2025-04-03T08:20:03.739204Z",
          "shell.execute_reply": "2025-04-03T08:20:05.144249Z"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(256, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic function to convert text to tokens and vice versa\n"
      ],
      "metadata": {
        "id": "WLkWp_qUTTxZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# text to tokens\n",
        "\n",
        "def text_to_token_ids(text,tokenizer):\n",
        "  encoded = tokenizer.encode(text,allowed_special = {'<|endoftext|>'})\n",
        "  encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
        "  return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids,tokenizer):\n",
        "  flat = token_ids.squeeze(0)\n",
        "  return tokenizer.decode(flat.tolist())\n",
        "\n",
        "start_context = \"Every effort moves you\"\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "token_ids = generate_text_simple(\n",
        "    model = model,\n",
        "    idx = text_to_token_ids(start_context,tokenizer),\n",
        "    max_new_tokens = 10,\n",
        "    context_size = GPT_CONFIG_124M[\"context_length\"]\n",
        ")\n",
        "\n",
        "print(\"output: \", token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFkSHO66M8ZJ",
        "outputId": "5f7d5dd5-af54-41e3-bd66-a2825812cdc5",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T08:20:10.385882Z",
          "iopub.execute_input": "2025-04-03T08:20:10.386227Z",
          "iopub.status.idle": "2025-04-03T08:20:12.772030Z",
          "shell.execute_reply.started": "2025-04-03T08:20:10.386197Z",
          "shell.execute_reply": "2025-04-03T08:20:12.771215Z"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output:  Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting into train data and validation data"
      ],
      "metadata": {
        "id": "YVYqJEUvSHe6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/LLM_From_Scratch/dataset1.txt\"\n",
        "with open(file_path, \"r\" , encoding = \"utf-8\") as file:\n",
        "  text_data = file.read()"
      ],
      "metadata": {
        "id": "JVKORVRKSdVs",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T08:20:44.413304Z",
          "iopub.execute_input": "2025-04-03T08:20:44.413591Z",
          "iopub.status.idle": "2025-04-03T08:20:44.428122Z",
          "shell.execute_reply.started": "2025-04-03T08:20:44.413568Z",
          "shell.execute_reply": "2025-04-03T08:20:44.427390Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "total_characters = len(text_data)\n",
        "total_tokens = len(tokenizer.encode(text_data))\n",
        "print(total_characters)\n",
        "print(total_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ncI-ZsNSLLB",
        "outputId": "ab10a22e-b24c-4e0b-9899-87f7d481402b",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T08:20:46.749838Z",
          "iopub.execute_input": "2025-04-03T08:20:46.750192Z",
          "iopub.status.idle": "2025-04-03T08:20:46.944155Z",
          "shell.execute_reply.started": "2025-04-03T08:20:46.750165Z",
          "shell.execute_reply": "2025-04-03T08:20:46.943365Z"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1606258\n",
            "437696\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_ratio = 0.9\n",
        "split_idx = int(train_ratio * len(text_data))\n",
        "train_data = text_data[:split_idx]\n",
        "val_data = text_data[split_idx:]\n"
      ],
      "metadata": {
        "id": "SMLqaZeHR646",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T08:20:49.023778Z",
          "iopub.execute_input": "2025-04-03T08:20:49.024084Z",
          "iopub.status.idle": "2025-04-03T08:20:49.028760Z",
          "shell.execute_reply.started": "2025-04-03T08:20:49.024059Z",
          "shell.execute_reply": "2025-04-03T08:20:49.027900Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating dataloader"
      ],
      "metadata": {
        "id": "d18YoMVHSkdj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = create_dataloader_v1(\n",
        "    train_data,\n",
        "    batch_size = 16,\n",
        "    max_length = GPT_CONFIG_124M['context_length'],\n",
        "    stride = GPT_CONFIG_124M['context_length'],\n",
        "    drop_last = True,\n",
        "    shuffle = True,\n",
        "    num_workers = 0\n",
        ")\n",
        "\n",
        "val_loader = create_dataloader_v1(\n",
        "    val_data,\n",
        "    batch_size = 16,\n",
        "    max_length = GPT_CONFIG_124M['context_length'],\n",
        "    stride = GPT_CONFIG_124M['context_length'],\n",
        "    drop_last = False,\n",
        "    shuffle = False,\n",
        "    num_workers = 0\n",
        ")"
      ],
      "metadata": {
        "id": "WPjRCByfStq4",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T08:20:51.482104Z",
          "iopub.execute_input": "2025-04-03T08:20:51.482397Z",
          "iopub.status.idle": "2025-04-03T08:20:51.827870Z",
          "shell.execute_reply.started": "2025-04-03T08:20:51.482375Z",
          "shell.execute_reply": "2025-04-03T08:20:51.827228Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train loader: \")\n",
        "c = 0\n",
        "for x,y in train_loader:\n",
        "  c += 1\n",
        "print(\"Number of training batches: \", c)\n",
        "\n",
        "c = 0\n",
        "print(\"Val loader: \")\n",
        "for x,y in val_loader:\n",
        "  c += 1\n",
        "print(\"Number of validation batches: \",c)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hI1jGzuhSt67",
        "outputId": "e3b2038c-c180-4b8a-9a51-41753f87be4c",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T08:20:54.564840Z",
          "iopub.execute_input": "2025-04-03T08:20:54.565158Z",
          "iopub.status.idle": "2025-04-03T08:20:54.586417Z",
          "shell.execute_reply.started": "2025-04-03T08:20:54.565133Z",
          "shell.execute_reply": "2025-04-03T08:20:54.585705Z"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loader: \n",
            "Number of training batches:  95\n",
            "Val loader: \n",
            "Number of validation batches:  11\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions to calculate loss"
      ],
      "metadata": {
        "id": "EeA7n-1JTb1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "  input_batch = input_batch.to(device)\n",
        "  target_batch = target_batch.to(device)\n",
        "  logits = model(input_batch)\n",
        "  loss = torch.nn.functional.cross_entropy(\n",
        "      logits.flatten(0,1), target_batch.flatten()\n",
        "  )\n",
        "  return loss\n"
      ],
      "metadata": {
        "id": "bjAu9ngqTzcu",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T08:20:58.459066Z",
          "iopub.execute_input": "2025-04-03T08:20:58.459351Z",
          "iopub.status.idle": "2025-04-03T08:20:58.463751Z",
          "shell.execute_reply.started": "2025-04-03T08:20:58.459328Z",
          "shell.execute_reply": "2025-04-03T08:20:58.462750Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# function to compute training and val loss\n",
        "\n",
        "def calc_loss_loader(data_loader, model, device, num_batches = None):\n",
        "  total_loss = 0.\n",
        "  if len(data_loader) == 0:\n",
        "    return float(\"nan\")\n",
        "  elif num_batches is None:\n",
        "    num_batches = len(data_loader)\n",
        "  else:\n",
        "    num_batches = min(num_batches, len(data_loader))\n",
        "\n",
        "  for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "    if i < num_batches:\n",
        "      loss = calc_loss_batch(\n",
        "          input_batch,target_batch,model,device\n",
        "      )\n",
        "      total_loss += loss.item()\n",
        "    else:\n",
        "      break\n",
        "\n",
        "  return total_loss / num_batches"
      ],
      "metadata": {
        "id": "LuS6AB6yUsTO",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T08:20:59.216306Z",
          "iopub.execute_input": "2025-04-03T08:20:59.216591Z",
          "iopub.status.idle": "2025-04-03T08:20:59.221562Z",
          "shell.execute_reply.started": "2025-04-03T08:20:59.216568Z",
          "shell.execute_reply": "2025-04-03T08:20:59.220755Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chossing CUDA if available"
      ],
      "metadata": {
        "id": "1tp1qoFnT4m9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "with torch.no_grad():\n",
        " train_loss = calc_loss_loader(train_loader, model, device)\n",
        " val_loss = calc_loss_loader(val_loader, model, device)\n",
        "print(\"Training loss:\", train_loss)\n",
        "print(\"Validation loss:\", val_loss)"
      ],
      "metadata": {
        "id": "kvJ8e4oBT2En",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed6326f3-9242-4256-aa2c-bb3cabd20aa1",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T08:21:01.902214Z",
          "iopub.execute_input": "2025-04-03T08:21:01.902501Z",
          "iopub.status.idle": "2025-04-03T08:21:22.382531Z",
          "shell.execute_reply.started": "2025-04-03T08:21:01.902480Z",
          "shell.execute_reply": "2025-04-03T08:21:22.381609Z"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 10.98212187917609\n",
            "Validation loss: 10.966888080943715\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the model on dataset1.txt"
      ],
      "metadata": {
        "id": "yyK2nwsZWNub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# main function for pretraining LLMs\n",
        "\n",
        "def train_model_simple(model, train_loader, val_loader, optimizer, device,\n",
        "                      num_epochs, eval_freq, eval_iter, start_context, tokenizer):\n",
        "  train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "  tokens_seen, global_step = 0, -1            #  initalising lists to store the losses\n",
        "  for epoch in range(num_epochs):  # starting of the iteration process\n",
        "    model.train()\n",
        "\n",
        "    for input_batch, target_batch in train_loader:\n",
        "      optimizer.zero_grad()     #  resets the loss gradient from previous epochs\n",
        "\n",
        "      loss = calc_loss_batch(\n",
        "          input_batch, target_batch, model, device\n",
        "      )\n",
        "\n",
        "      loss.backward()  # calculatesthe loss gradient\n",
        "      optimizer.step()  # upodates the model weights using loss gradients\n",
        "      tokens_seen += input_batch.numel()\n",
        "      global_step += 1\n",
        "\n",
        "      if global_step % eval_freq == 0:  # optional evaluation step\n",
        "        train_loss, eval_loss = evaluate_model(\n",
        "            model, train_loader, val_loader, device, eval_iter\n",
        "        )\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(eval_loss)\n",
        "        track_tokens_seen.append(tokens_seen)\n",
        "        print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "              f\"Train loss {train_loss:.3f}, \"\n",
        "              f\"Val loss {eval_loss:.3f}\"\n",
        "              )\n",
        "    generate_and_print_sample(model, tokenizer, device, start_context)  # prints sample text aafter each epoch\n",
        "\n",
        "  return train_losses, val_losses, track_tokens_seen\n"
      ],
      "metadata": {
        "id": "27AuofUdUH7k",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T08:21:31.054217Z",
          "iopub.execute_input": "2025-04-03T08:21:31.054520Z",
          "iopub.status.idle": "2025-04-03T08:21:31.060593Z",
          "shell.execute_reply.started": "2025-04-03T08:21:31.054497Z",
          "shell.execute_reply": "2025-04-03T08:21:31.059662Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# defining evaluate_model\n",
        "\n",
        "# this corresponds to step 7 in the figure where we print the lossees to avaluate the performance of training the model\n",
        "\n",
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "  model.eval() # Dropout is disable during the evaluation process for stable reslts\n",
        "  with torch.no_grad():\n",
        "    train_loss = calc_loss_loader( # disables gradient tracking because we dont need it in evaluation\n",
        "        train_loader, model, device, num_batches = eval_iter\n",
        "    )\n",
        "    val_loss = calc_loss_loader(\n",
        "        val_loader, model, device, num_batches=eval_iter\n",
        "    )\n",
        "\n",
        "  model.train()\n",
        "  return train_loss, val_loss"
      ],
      "metadata": {
        "id": "z68f0RMxT7-X",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T08:21:33.688681Z",
          "iopub.execute_input": "2025-04-03T08:21:33.689012Z",
          "iopub.status.idle": "2025-04-03T08:21:33.693544Z",
          "shell.execute_reply.started": "2025-04-03T08:21:33.688983Z",
          "shell.execute_reply": "2025-04-03T08:21:33.692508Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# generate_and_print_sample function takes a text snippet and converts it into token ids and feed it to model to generate a text\n",
        "\n",
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        "  model.eval()\n",
        "  context_size = model.pos_emb.weight.shape[0]\n",
        "  encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "  with torch.no_grad():\n",
        "    token_ids = generate_text_simple(\n",
        "        model = model,\n",
        "        idx = encoded,\n",
        "        max_new_tokens = 50, context_size = context_size\n",
        "    )\n",
        "\n",
        "  decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        "  print(decoded_text.replace(\"\\n\", \" \"))\n",
        "  model.train()"
      ],
      "metadata": {
        "id": "mWFJ7kjZWS2-",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T08:21:34.324626Z",
          "iopub.execute_input": "2025-04-03T08:21:34.324970Z",
          "iopub.status.idle": "2025-04-03T08:21:34.330113Z",
          "shell.execute_reply.started": "2025-04-03T08:21:34.324916Z",
          "shell.execute_reply": "2025-04-03T08:21:34.329198Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training for 7 epochs"
      ],
      "metadata": {
        "id": "Ah9Dd4NvrLHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# trainng the GPTModel for 10 epochs\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(), lr = 0.0004, weight_decay = 0.1\n",
        ")\n",
        "num_epochs = 7\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "    model, train_loader, val_loader, optimizer, device, num_epochs = num_epochs, eval_freq = 5, eval_iter = 5,\n",
        "    start_context = \"Every effort moves you\", tokenizer = tokenizer\n",
        ")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T09:36:10.692199Z",
          "iopub.execute_input": "2025-04-03T09:36:10.692506Z",
          "iopub.status.idle": "2025-04-03T09:51:29.101910Z",
          "shell.execute_reply.started": "2025-04-03T09:36:10.692478Z",
          "shell.execute_reply": "2025-04-03T09:51:29.101085Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uc6QEkC6E5Nj",
        "outputId": "937fb9fd-4704-4039-a779-b323cf454a3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 9.431, Val loss 9.543\n",
            "Ep 1 (Step 000005): Train loss 7.721, Val loss 7.750\n",
            "Ep 1 (Step 000010): Train loss 6.662, Val loss 6.652\n",
            "Ep 1 (Step 000015): Train loss 6.203, Val loss 6.238\n",
            "Ep 1 (Step 000020): Train loss 6.217, Val loss 6.145\n",
            "Ep 1 (Step 000025): Train loss 6.017, Val loss 6.095\n",
            "Ep 1 (Step 000030): Train loss 5.999, Val loss 5.995\n",
            "Ep 1 (Step 000035): Train loss 5.898, Val loss 5.894\n",
            "Ep 1 (Step 000040): Train loss 5.650, Val loss 5.827\n",
            "Ep 1 (Step 000045): Train loss 5.796, Val loss 5.739\n",
            "Ep 1 (Step 000050): Train loss 5.523, Val loss 5.666\n",
            "Ep 1 (Step 000055): Train loss 5.496, Val loss 5.631\n",
            "Ep 1 (Step 000060): Train loss 5.499, Val loss 5.545\n",
            "Ep 1 (Step 000065): Train loss 5.411, Val loss 5.506\n",
            "Ep 1 (Step 000070): Train loss 5.328, Val loss 5.468\n",
            "Ep 1 (Step 000075): Train loss 5.285, Val loss 5.405\n",
            "Ep 1 (Step 000080): Train loss 5.278, Val loss 5.372\n",
            "Ep 1 (Step 000085): Train loss 5.210, Val loss 5.313\n",
            "Ep 1 (Step 000090): Train loss 5.216, Val loss 5.309\n",
            "Every effort moves you have been          “I have been a little to be very                   “I am.“I am\n",
            "Ep 2 (Step 000095): Train loss 4.940, Val loss 5.266\n",
            "Ep 2 (Step 000100): Train loss 5.068, Val loss 5.263\n",
            "Ep 2 (Step 000105): Train loss 5.084, Val loss 5.239\n",
            "Ep 2 (Step 000110): Train loss 5.026, Val loss 5.208\n",
            "Ep 2 (Step 000115): Train loss 5.047, Val loss 5.191\n",
            "Ep 2 (Step 000120): Train loss 4.874, Val loss 5.169\n",
            "Ep 2 (Step 000125): Train loss 4.930, Val loss 5.165\n",
            "Ep 2 (Step 000130): Train loss 4.936, Val loss 5.138\n",
            "Ep 2 (Step 000135): Train loss 4.822, Val loss 5.121\n",
            "Ep 2 (Step 000140): Train loss 4.859, Val loss 5.143\n",
            "Ep 2 (Step 000145): Train loss 4.754, Val loss 5.108\n",
            "Ep 2 (Step 000150): Train loss 4.783, Val loss 5.073\n",
            "Ep 2 (Step 000155): Train loss 4.656, Val loss 5.062\n",
            "Ep 2 (Step 000160): Train loss 4.822, Val loss 5.046\n",
            "Ep 2 (Step 000165): Train loss 4.689, Val loss 5.048\n",
            "Ep 2 (Step 000170): Train loss 4.581, Val loss 5.043\n",
            "Ep 2 (Step 000175): Train loss 4.658, Val loss 5.014\n",
            "Ep 2 (Step 000180): Train loss 4.640, Val loss 4.997\n",
            "Ep 2 (Step 000185): Train loss 4.587, Val loss 4.989\n",
            "Every effort moves you have been and I am not be and I have been and I am not to the and I amiable.              “I am not to be in the other\n",
            "Ep 3 (Step 000190): Train loss 4.465, Val loss 4.987\n",
            "Ep 3 (Step 000195): Train loss 4.461, Val loss 4.971\n",
            "Ep 3 (Step 000200): Train loss 4.350, Val loss 4.976\n",
            "Ep 3 (Step 000205): Train loss 4.348, Val loss 4.970\n",
            "Ep 3 (Step 000210): Train loss 4.586, Val loss 4.985\n",
            "Ep 3 (Step 000215): Train loss 4.479, Val loss 4.955\n",
            "Ep 3 (Step 000220): Train loss 4.458, Val loss 4.955\n",
            "Ep 3 (Step 000225): Train loss 4.382, Val loss 4.956\n",
            "Ep 3 (Step 000230): Train loss 4.521, Val loss 4.947\n",
            "Ep 3 (Step 000235): Train loss 4.381, Val loss 4.931\n",
            "Ep 3 (Step 000240): Train loss 4.328, Val loss 4.920\n",
            "Ep 3 (Step 000245): Train loss 4.456, Val loss 4.910\n",
            "Ep 3 (Step 000250): Train loss 4.308, Val loss 4.913\n",
            "Ep 3 (Step 000255): Train loss 4.236, Val loss 4.920\n",
            "Ep 3 (Step 000260): Train loss 4.251, Val loss 4.892\n",
            "Ep 3 (Step 000265): Train loss 4.252, Val loss 4.884\n",
            "Ep 3 (Step 000270): Train loss 4.258, Val loss 4.894\n",
            "Ep 3 (Step 000275): Train loss 4.188, Val loss 4.889\n",
            "Ep 3 (Step 000280): Train loss 4.156, Val loss 4.849\n",
            "Every effort moves you, and I have been to be a little to be a to be a little longer.”  “I am sure,” said Joe, “I am sure,”  “I am\n",
            "Ep 4 (Step 000285): Train loss 4.138, Val loss 4.851\n",
            "Ep 4 (Step 000290): Train loss 4.141, Val loss 4.875\n",
            "Ep 4 (Step 000295): Train loss 4.197, Val loss 4.850\n",
            "Ep 4 (Step 000300): Train loss 4.039, Val loss 4.856\n",
            "Ep 4 (Step 000305): Train loss 4.038, Val loss 4.844\n",
            "Ep 4 (Step 000310): Train loss 4.162, Val loss 4.832\n",
            "Ep 4 (Step 000315): Train loss 3.882, Val loss 4.841\n",
            "Ep 4 (Step 000320): Train loss 3.963, Val loss 4.816\n",
            "Ep 4 (Step 000325): Train loss 3.846, Val loss 4.801\n",
            "Ep 4 (Step 000330): Train loss 4.045, Val loss 4.806\n",
            "Ep 4 (Step 000335): Train loss 3.866, Val loss 4.806\n",
            "Ep 4 (Step 000340): Train loss 3.886, Val loss 4.800\n",
            "Ep 4 (Step 000345): Train loss 3.886, Val loss 4.786\n",
            "Ep 4 (Step 000350): Train loss 3.875, Val loss 4.806\n",
            "Ep 4 (Step 000355): Train loss 3.873, Val loss 4.785\n",
            "Ep 4 (Step 000360): Train loss 3.824, Val loss 4.785\n",
            "Ep 4 (Step 000365): Train loss 3.789, Val loss 4.765\n",
            "Ep 4 (Step 000370): Train loss 3.772, Val loss 4.741\n",
            "Ep 4 (Step 000375): Train loss 3.705, Val loss 4.722\n",
            "Every effort moves you are not to be so much as to be of the other.”  “I am afraid you are to be so much to be so much as well.”  “I am afraid of the  \n",
            "Ep 5 (Step 000380): Train loss 3.664, Val loss 4.718\n",
            "Ep 5 (Step 000385): Train loss 3.595, Val loss 4.717\n",
            "Ep 5 (Step 000390): Train loss 3.749, Val loss 4.746\n",
            "Ep 5 (Step 000395): Train loss 3.605, Val loss 4.754\n",
            "Ep 5 (Step 000400): Train loss 3.533, Val loss 4.743\n",
            "Ep 5 (Step 000405): Train loss 3.486, Val loss 4.757\n",
            "Ep 5 (Step 000410): Train loss 3.547, Val loss 4.750\n",
            "Ep 5 (Step 000415): Train loss 3.379, Val loss 4.739\n",
            "Ep 5 (Step 000420): Train loss 3.522, Val loss 4.736\n",
            "Ep 5 (Step 000425): Train loss 3.508, Val loss 4.757\n",
            "Ep 5 (Step 000430): Train loss 3.342, Val loss 4.726\n",
            "Ep 5 (Step 000435): Train loss 3.372, Val loss 4.719\n",
            "Ep 5 (Step 000440): Train loss 3.378, Val loss 4.739\n",
            "Ep 5 (Step 000445): Train loss 3.304, Val loss 4.729\n",
            "Ep 5 (Step 000450): Train loss 3.302, Val loss 4.696\n",
            "Ep 5 (Step 000455): Train loss 3.299, Val loss 4.676\n",
            "Ep 5 (Step 000460): Train loss 3.310, Val loss 4.728\n",
            "Ep 5 (Step 000465): Train loss 3.310, Val loss 4.694\n",
            "Ep 5 (Step 000470): Train loss 3.260, Val loss 4.690\n",
            "Every effort moves you, and to be in the world of the world, and the other person, and the other man who had the other, and the other, and the of the world of the world, and the other, and the the\n",
            "Ep 6 (Step 000475): Train loss 3.162, Val loss 4.699\n",
            "Ep 6 (Step 000480): Train loss 3.150, Val loss 4.706\n",
            "Ep 6 (Step 000485): Train loss 3.114, Val loss 4.731\n",
            "Ep 6 (Step 000490): Train loss 3.164, Val loss 4.739\n",
            "Ep 6 (Step 000495): Train loss 3.097, Val loss 4.738\n",
            "Ep 6 (Step 000500): Train loss 3.013, Val loss 4.759\n",
            "Ep 6 (Step 000505): Train loss 2.950, Val loss 4.758\n",
            "Ep 6 (Step 000510): Train loss 2.989, Val loss 4.760\n",
            "Ep 6 (Step 000515): Train loss 2.932, Val loss 4.771\n",
            "Ep 6 (Step 000520): Train loss 2.946, Val loss 4.775\n",
            "Ep 6 (Step 000525): Train loss 2.916, Val loss 4.755\n",
            "Ep 6 (Step 000530): Train loss 2.954, Val loss 4.747\n",
            "Ep 6 (Step 000535): Train loss 2.886, Val loss 4.749\n",
            "Ep 6 (Step 000540): Train loss 2.946, Val loss 4.763\n",
            "Ep 6 (Step 000545): Train loss 2.876, Val loss 4.733\n",
            "Ep 6 (Step 000550): Train loss 2.840, Val loss 4.777\n",
            "Ep 6 (Step 000555): Train loss 2.738, Val loss 4.759\n",
            "Ep 6 (Step 000560): Train loss 2.743, Val loss 4.763\n",
            "Ep 6 (Step 000565): Train loss 2.731, Val loss 4.751\n",
            "Every effort moves you’t be.”  “I am not to be so,” said I, “and I have have been so, and I have been so dear me to-morrow with you, and I\n",
            "Ep 7 (Step 000570): Train loss 2.697, Val loss 4.763\n",
            "Ep 7 (Step 000575): Train loss 2.642, Val loss 4.793\n",
            "Ep 7 (Step 000580): Train loss 2.600, Val loss 4.820\n",
            "Ep 7 (Step 000585): Train loss 2.502, Val loss 4.847\n",
            "Ep 7 (Step 000590): Train loss 2.469, Val loss 4.847\n",
            "Ep 7 (Step 000595): Train loss 2.530, Val loss 4.842\n",
            "Ep 7 (Step 000600): Train loss 2.399, Val loss 4.850\n",
            "Ep 7 (Step 000605): Train loss 2.417, Val loss 4.872\n",
            "Ep 7 (Step 000610): Train loss 2.436, Val loss 4.863\n",
            "Ep 7 (Step 000615): Train loss 2.334, Val loss 4.899\n",
            "Ep 7 (Step 000620): Train loss 2.460, Val loss 4.905\n",
            "Ep 7 (Step 000625): Train loss 2.282, Val loss 4.893\n",
            "Ep 7 (Step 000630): Train loss 2.382, Val loss 4.879\n",
            "Ep 7 (Step 000635): Train loss 2.239, Val loss 4.916\n",
            "Ep 7 (Step 000640): Train loss 2.258, Val loss 4.870\n",
            "Ep 7 (Step 000645): Train loss 2.297, Val loss 4.912\n",
            "Ep 7 (Step 000650): Train loss 2.275, Val loss 4.900\n",
            "Ep 7 (Step 000655): Train loss 2.207, Val loss 4.892\n",
            "Ep 7 (Step 000660): Train loss 2.205, Val loss 4.865\n",
            "Every effort moves you know,” said Mr. Jaggers, “I’ll do with you not to you, and see him.”  “I said to, “I am sure,” said I, �\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses, num_epochs):\n",
        " fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        " ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
        " ax1.plot(\n",
        " epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\"\n",
        " )\n",
        " ax1.set_xlabel(\"Epochs\")\n",
        " ax1.set_ylabel(\"Loss\")\n",
        " ax1.legend(loc=\"upper right\")\n",
        " ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "\n",
        " plt.title(f\"Model trained for {num_epochs} epochs\")\n",
        "\n",
        " ax2 = ax1.twiny()\n",
        " ax2.plot(tokens_seen, train_losses, alpha=0)\n",
        " ax2.set_xlabel(\"Tokens seen\")\n",
        " fig.tight_layout()\n",
        " plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "oz-fUnZPGfA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses,num_epochs)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T09:51:29.104123Z",
          "iopub.execute_input": "2025-04-03T09:51:29.104346Z",
          "iopub.status.idle": "2025-04-03T09:51:29.529393Z",
          "shell.execute_reply.started": "2025-04-03T09:51:29.104327Z",
          "shell.execute_reply": "2025-04-03T09:51:29.528598Z"
        },
        "id": "6Wm2RvidE5Nj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "990844d1-e339-4803-995d-651ece2ad1d0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function to geenrate text (Comprising of temperature and top k sampling)"
      ],
      "metadata": {
        "id": "j5vpi_dhrTYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(\"cpu\")\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "lPUim9tcrhIF",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T09:53:53.335098Z",
          "iopub.execute_input": "2025-04-03T09:53:53.335415Z",
          "iopub.status.idle": "2025-04-03T09:53:53.348733Z",
          "shell.execute_reply.started": "2025-04-03T09:53:53.335390Z",
          "shell.execute_reply": "2025-04-03T09:53:53.347580Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36f635e8-8063-44a1-b95d-7869319172f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(256, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(model, idx, max_new_tokens, context_size, temperature = 0.0, top_k = None, eos_id = None):\n",
        "  for _ in range(max_new_tokens):\n",
        "    idx_cond = idx[:,-context_size:]\n",
        "    with torch.no_grad():\n",
        "      logits = model(idx_cond)\n",
        "    logits = logits[:, -1, :]\n",
        "    if top_k is not None:\n",
        "      top_logits,_ = torch.topk(logits,top_k)\n",
        "      min_value = top_logits[:, -1]\n",
        "      logits = torch.where(\n",
        "          logits < min_value,\n",
        "          torch.tensor(float('-inf')).to(logits.device),\n",
        "          logits\n",
        "      )\n",
        "    if temperature > 0.0:\n",
        "      logits = logits / temperature\n",
        "      probs = torch.softmax(logits, dim = -1)\n",
        "      idx_next = torch.multinomial(probs, num_samples = 1)\n",
        "    else:\n",
        "      idx_next = torch.argmax(logits, dim = -1, keepdim = True)\n",
        "    if idx_next == eos_id:\n",
        "      break\n",
        "    idx = torch.cat((idx,idx_next), dim = -1)\n",
        "  return idx"
      ],
      "metadata": {
        "id": "3Y_TKwXwi9mp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "token_ids = generate(\n",
        "    model = model,\n",
        "    idx = text_to_token_ids(\"Hello, I am\", tokenizer),\n",
        "    max_new_tokens = 15,\n",
        "    context_size = GPT_CONFIG_124M['context_length'],\n",
        "    top_k = 25,\n",
        "    temperature = 1.4\n",
        ")\n",
        "print(\"output: \", token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "id": "Kph__3ZxrmuO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c14c68d7-4375-41e8-c74b-715917c4155f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output:  Hello, I am in dancing is, as you at\n",
            "be renewed.”\n",
            "\n",
            "\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving the model"
      ],
      "metadata": {
        "id": "VUxMQ0Jcx2-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save({\n",
        "    \"epochs\": num_epochs,\n",
        "    \"model_state_dict\": model.state_dict(),\n",
        "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "  },\n",
        "    \"model_and_optimizer.pth\"\n",
        ")"
      ],
      "metadata": {
        "id": "vMsVH37W2hWE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load(\"model_and_optimizer.pth\", map_location=device)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
        "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "model.train();"
      ],
      "metadata": {
        "id": "CgW4v6cF3bT7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving to Cloud"
      ],
      "metadata": {
        "id": "aedNSKQqx7i4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "B003UongRM_Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f376dde-1a2a-474a-b737-0a6691252a37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save({\n",
        "    \"epochs\": num_epochs,\n",
        "    \"model_state_dict\": model.state_dict(),\n",
        "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "}, \"/content/drive/MyDrive/model_and_optimizer.pth\")"
      ],
      "metadata": {
        "id": "oAIiIOmM2ctV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## loading from cload and testing"
      ],
      "metadata": {
        "id": "PpCNUEyHTWEi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Bhavya171/LLM_From_Scratch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c70486bf-27be-4116-dfd8-68945edae716",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T08:19:11.439627Z",
          "iopub.execute_input": "2025-04-03T08:19:11.439916Z",
          "iopub.status.idle": "2025-04-03T08:19:12.623540Z",
          "shell.execute_reply.started": "2025-04-03T08:19:11.439883Z",
          "shell.execute_reply": "2025-04-03T08:19:12.622487Z"
        },
        "id": "uieu_7YzTpyb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'LLM_From_Scratch'...\n",
            "remote: Enumerating objects: 60, done.\u001b[K\n",
            "remote: Counting objects: 100% (60/60), done.\u001b[K\n",
            "remote: Compressing objects: 100% (57/57), done.\u001b[K\n",
            "remote: Total 60 (delta 24), reused 4 (delta 1), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (60/60), 2.06 MiB | 5.09 MiB/s, done.\n",
            "Resolving deltas: 100% (24/24), done.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%cd LLM_From_Scratch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd0364ab-1792-4352-e47e-2962b78e41ef",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T08:19:42.682775Z",
          "iopub.execute_input": "2025-04-03T08:19:42.683111Z",
          "iopub.status.idle": "2025-04-03T08:19:42.688597Z",
          "shell.execute_reply.started": "2025-04-03T08:19:42.683082Z",
          "shell.execute_reply": "2025-04-03T08:19:42.687673Z"
        },
        "id": "kw9BXdTbTpyd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/LLM_From_Scratch\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d103d73-1c5b-49e7-ff9a-31c024587e47",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T08:19:52.207123Z",
          "iopub.execute_input": "2025-04-03T08:19:52.207423Z",
          "iopub.status.idle": "2025-04-03T08:19:56.338900Z",
          "shell.execute_reply.started": "2025-04-03T08:19:52.207401Z",
          "shell.execute_reply": "2025-04-03T08:19:56.338073Z"
        },
        "id": "Y7tUQ0ArTpye"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,\n",
        "    \"context_length\": 256,\n",
        "    \"emb_dim\": 768,\n",
        "    \"n_heads\": 12,\n",
        "    \"n_layers\": 12,\n",
        "    \"drop_rate\": 0.1,\n",
        "    \"qkv_bias\": False\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "id": "aVYXSc73UWTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import tiktoken\n",
        "from previous_chapters import GPTModel\n",
        "from previous_chapters import generate_text_simple"
      ],
      "metadata": {
        "id": "z5L_NqUJTY6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --no-cache-dir gdown\n",
        "!gdown --id 1g-CgaIaFtRfTFkIhTmt_HRVwSDheSUNN -O model_and_optimizer.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4ct0nXqS-JD",
        "outputId": "0e2876b1-8a3e-4da1-b773-d89925b7fa0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.1.31)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1g-CgaIaFtRfTFkIhTmt_HRVwSDheSUNN\n",
            "From (redirected): https://drive.google.com/uc?id=1g-CgaIaFtRfTFkIhTmt_HRVwSDheSUNN&confirm=t&uuid=ad20a703-06a6-45fd-84c8-5f0acc3efa4b\n",
            "To: /content/LLM_From_Scratch/model_and_optimizer.pth\n",
            "100% 1.95G/1.95G [00:15<00:00, 122MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  # Importing the model architecture\n",
        "\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "\n",
        "checkpoint = torch.load(\"model_and_optimizer.pth\", map_location=\"cuda\", weights_only=False)  # Change to \"cpu\" if needed\n",
        "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "\n",
        "\n",
        "model.eval()\n",
        "\n",
        "print(\"✅ Model successfully loaded!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpKUh423TCvl",
        "outputId": "697bcc3c-f981-4b9d-9125-8b781dfad7a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model successfully loaded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# text to tokens\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def text_to_token_ids(text,tokenizer):\n",
        "  encoded = tokenizer.encode(text,allowed_special = {'<|endoftext|>'})\n",
        "  encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
        "  return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids,tokenizer):\n",
        "  flat = token_ids.squeeze(0)\n",
        "  return tokenizer.decode(flat.tolist())\n",
        "\n",
        "start_context = \"Every effort moves you\"\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "token_ids = generate_text_simple(\n",
        "    model = model,\n",
        "    idx = text_to_token_ids(start_context,tokenizer),\n",
        "    max_new_tokens = 10,\n",
        "    context_size = GPT_CONFIG_124M[\"context_length\"]\n",
        ")\n",
        "\n",
        "print(\"output: \", token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "id": "puz9Ut1QdVCW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc7f3f88-fc90-4733-bdc0-42d247b181f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output:  Every effort moves you know,” said Mr. Jaggers,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(model, idx, max_new_tokens, context_size, temperature = 0.0, top_k = None, eos_id = None):\n",
        "  for _ in range(max_new_tokens):\n",
        "    idx_cond = idx[:,-context_size:]\n",
        "    with torch.no_grad():\n",
        "      logits = model(idx_cond)\n",
        "    logits = logits[:, -1, :]\n",
        "    if top_k is not None:\n",
        "      top_logits,_ = torch.topk(logits,top_k)\n",
        "      min_value = top_logits[:, -1]\n",
        "      logits = torch.where(\n",
        "          logits < min_value,\n",
        "          torch.tensor(float('-inf')).to(logits.device),\n",
        "          logits\n",
        "      )\n",
        "    if temperature > 0.0:\n",
        "      logits = logits / temperature\n",
        "      probs = torch.softmax(logits, dim = -1)\n",
        "      idx_next = torch.multinomial(probs, num_samples = 1)\n",
        "    else:\n",
        "      idx_next = torch.argmax(logits, dim = -1, keepdim = True)\n",
        "    if idx_next == eos_id:\n",
        "      break\n",
        "    idx = torch.cat((idx,idx_next), dim = -1)\n",
        "  return idx"
      ],
      "metadata": {
        "id": "3QVsoXSMTSoE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "token_ids = generate(\n",
        "    model = model,\n",
        "    idx = text_to_token_ids(\"Hello, I am\", tokenizer),\n",
        "    max_new_tokens = 15,\n",
        "    context_size = GPT_CONFIG_124M['context_length'],\n",
        "    top_k = 25,\n",
        "    temperature = 1.4\n",
        ")\n",
        "print(\"output: \", token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "530f7d1d-a07e-457e-e531-06c186f33597",
        "id": "F2TVuwP2TSoF"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output:  Hello, I am, in your very glad to my opinion, I am, at Mr.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N42tURVZUJjT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}